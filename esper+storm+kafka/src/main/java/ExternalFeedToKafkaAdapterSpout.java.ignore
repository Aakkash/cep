import backtype.storm.spout.SpoutOutputCollector;
import backtype.storm.task.TopologyContext;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseRichSpout;
import backtype.storm.tuple.Fields;

import java.util.Map;

import static backtype.storm.utils.Utils.tuple;

public class ExternalFeedToKafkaAdapterSpout extends BaseRichSpout
{
    private static final long serialVersionUID = 1L;

    private transient SpoutOutputCollector collector;

    public ExternalFeedToKafkaAdapterSpout(String brokerConnectString,
                                           String topicName,
                                           String serializerClass) {
    }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer)
    {
        declarer.declare(new Fields("record"));

    }

    @Override
    public void nextTuple()
    {
        String wordToEmit = "default";
        if (Math.random() > defaultWordEmissionProbability) {
            wordToEmit = specialWord  + Math.floor ((Math.random() * 100));
        }
        collector.emit( tuple(wordToEmit));
        System.out.println("+++++emitted: " + wordToEmit);

        try {
            Thread.sleep(sleepMillisecsAfterEmission);
        } catch (InterruptedException e) {
            System.out.println("Fatal error");
            System.exit(-1);
        }
    }

    @Override
    public void open(@SuppressWarnings("rawtypes") Map conf,
                     TopologyContext context,
                     SpoutOutputCollector collector)
    {

    }

    @Override
    public void close() {}

    @Override
    public void ack(Object msgId) {}

    @Override
    public void fail(Object msgId) {}
}
